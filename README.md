# LU (Layer Understanding)

**LU** es un framework modular y liviano dise√±ado para aprovechar el potencial de los modelos de lenguaje (LLMs) manteniendo el control total sobre las conversaciones en chatbots. Utiliza la comprensi√≥n sem√°ntica avanzada de los LLMs para generar interacciones naturales y humanas, evitando que el di√°logo se desv√≠e del prop√≥sito definido.

> **Nota**: Aunque el desarrollo del proyecto contin√∫a bajo el nombre **LU**, el paquete publicado en npm se llama `ludmi` debido a un conflicto de nombres con otro paquete existente.

## Objetivo

En el contexto actual de la inteligencia artificial, los chatbots tienden a desviarse del tema cuando operan con libertad total. **LU** nace para resolver este desaf√≠o, combinando lo mejor del entendimiento conversacional con estructuras de control precisas:

- **Controlar la conversaci√≥n**: Aprovecha la comprensi√≥n sem√°ntica de los LLMs para guiar y limitar las respuestas del chatbot de manera inteligente.

- **Simular libertad**: Ofrece interacciones fluidas y naturales sin perder el control del flujo conversacional.

- **Ejecutar acciones personalizadas**: Permite ejecutar acciones espec√≠ficas definidas por el desarrollador seg√∫n el tema clasificado.

- **Enriquecer las respuestas**: Integra conocimiento externo desde bases de datos u otras fuentes para generar respuestas con informaci√≥n precisa y contextual.

## Caracter√≠sticas

### Comprensi√≥n y control del di√°logo
LU mantiene el foco conversacional mediante un sistema de clasificaci√≥n inteligente que analiza cada mensaje del usuario y determina el t√≥pico principal. Esta comprensi√≥n sem√°ntica permite guiar las respuestas, orquestar acciones personalizadas y asegurar que el chatbot act√∫e con coherencia seg√∫n el contexto establecido.

### Gesti√≥n de contexto y memoria
LU conserva el historial completo de la conversaci√≥n para mantener la coherencia entre turnos, adaptando las respuestas a lo que ya se ha discutido e integrando informaci√≥n del contexto cuando sea necesario para una experiencia conversacional fluida.

### Integraci√≥n con OpenAI
Permite generar respuestas naturales y obtener embeddings sem√°nticos de texto utilizando los modelos de OpenAI. Esta integraci√≥n es clave para la recuperaci√≥n inteligente de informaci√≥n y la clasificaci√≥n precisa de temas conversacionales.

### Recuperaci√≥n inteligente de conocimiento (Retriever + RAG)
LU puede recuperar fragmentos relevantes desde una base de conocimiento especializada para luego combinar estos datos con el mensaje del usuario y el historial conversacional, generando respuestas enriquecidas y fundamentadas en informaci√≥n espec√≠fica.

### Construcci√≥n de bases de conocimiento embebidas
LU proporciona herramientas para generar bases de conocimiento personalizadas con embeddings sem√°nticos:

- **`knowledgeBaseByText`**: Divide textos largos en fragmentos con solapamiento inteligente y calcula su representaci√≥n sem√°ntica para recuperaci√≥n eficiente.

- **`knowledgeBaseByJSON`**: Procesa estructuras JSON complejas, concatena el contenido de los elementos y los transforma en fragmentos embebidos listos para recuperaci√≥n contextual.

## Uso b√°sico

### Importaci√≥n

Para comenzar a usar LU, importa la funci√≥n principal `orchestrator`:

```javascript
const { orchestrator } = require("ludmi");

const response = await orchestrator({
  metadata,
  topics,
  input,
  userData,
  history,
  sizeHistory,
  actions
});
```

### El Orquestador

El **orquestador** es el n√∫cleo de LU que coordina todo el flujo conversacional. Analiza la entrada del usuario, clasifica el t√≥pico, gestiona el historial y ejecuta acciones espec√≠ficas seg√∫n el contexto.

**Par√°metros principales:**
- `topics`: JSON con los t√≥picos para clasificar la entrada del usuario
- `input`: El mensaje del usuario (string)
- `history`: Historial de mensajes de la conversaci√≥n
- `sizeHistory`: Tama√±o m√°ximo del historial a considerar
- `userData`: Variables y datos del usuario
- `metadata`: Contexto adicional (ej: a√±o actual, configuraciones)
- `actions`: Acciones a ejecutar seg√∫n el t√≥pico clasificado

**Lo que devuelve:**
- `topic`: El t√≥pico clasificado
- `revised_prompt`: Entrada enriquecida con contexto
- `price`: Costo de la operaci√≥n en USD
- Historial y datos actualizados

### Enriquecimiento contextual

LU enriquece autom√°ticamente la entrada del usuario combin√°ndola con el historial conversacional y la metadata disponible, generando un `revised_prompt` que incluye contexto relevante para mejorar la comprensi√≥n y calidad de la respuesta.

## Gu√≠a paso a paso: Creando tu primer bot

Vamos a crear **Tomy**, un bot verdulero que te ayude a entender c√≥mo integrar LU en tu proyecto.

### Paso 1: Instalaci√≥n

```bash
npm install ludmi
```

### Paso 2: Configuraci√≥n de OpenAI

Crea un archivo `.env` en la ra√≠z de tu proyecto con tus credenciales de OpenAI:

```env
OPENAI_API_KEY=sk-abc123def
OPENAI_ORGANIZATION=org-456ghi789
```

### Paso 3: Definir los t√≥picos

Crea un archivo `topics.json` con los temas que tu bot puede manejar:

```json
[
  {
    "name": "Comienzo",
    "description": "El usuario saluda con el objetivo de iniciar una conversaci√≥n. Ejemplo: 'Hola'."
  },
  {
    "name": "Cierre",
    "description": "El usuario saluda con el objetivo de terminar una conversaci√≥n. Ejemplo: 'Chau', 'Muchas gracias por todo', etc."
  },
  {
    "name": "Consulta_Producto",
    "description": "El usuario pregunta sobre verduras, frutas, precios o disponibilidad. Ejemplo: '¬øTienen tomates?', '¬øCu√°nto cuesta la lechuga?'."
  },
  {
    "name": "Pedido",
    "description": "El usuario quiere realizar un pedido o compra. Ejemplo: 'Quiero comprar 2 kilos de papas'."
  }
]
```

### Paso 4: Implementaci√≥n b√°sica

```javascript
import { orchestrator } from 'ludmi';
import topics from './topics.json';

const response = await orchestrator({
  history,
  input,
  sizeHistory: 5,
  topics,
  userData,
  actions: {},
  metadata: {
    currentYear: Date.now(),
    mainTheme: "Soy Tomy, un asistente especializado en venta de verduras y frutas frescas."
  }
});
```

### Estructura del historial

El historial debe seguir este formato:

```javascript
const history = [
  {
    role: "assistant",
    content: "¬°Hola! Soy Tomy, tu verdulero virtual. ¬øEn qu√© puedo ayudarte?"
  },
  {
    role: "user", 
    content: "¬øTienen tomates frescos?"
  }
];
```

### Respuesta del orquestador

LU devuelve una respuesta estructurada con toda la informaci√≥n procesada:

```json
{
  "price": {
    "unit": "USD",
    "value": 0.000080925
  },
  "data": {
    "topic": "Consulta_Producto",
    "input": "tienen tomates frescos?",
    "revised_prompt": "¬øTienen tomates frescos disponibles para la venta?",
    "history": [
      {
        "role": "assistant",
        "content": "¬°Hola! Soy Tomy, tu verdulero virtual. ¬øEn qu√© puedo ayudarte?"
      },
      {
        "role": "user",
        "content": "tienen tomates frescos?"
      }
    ],
    "userData": {}
  }
}
```

### Elementos clave de la respuesta

- **`topic`**: T√≥pico clasificado autom√°ticamente por LU
- **`revised_prompt`**: Versi√≥n mejorada de la entrada del usuario
- **`price`**: Costo de la operaci√≥n para control de gastos
- **`history`**: Historial actualizado de la conversaci√≥n

Con estos pasos b√°sicos ya tienes a Tomy funcionando y clasificando las intenciones de tus usuarios. En las siguientes secciones veremos c√≥mo a√±adir acciones personalizadas y bases de conocimiento.

## Acciones personalizadas

Las **acciones** te permiten ejecutar l√≥gica espec√≠fica cuando se clasifica un t√≥pico determinado. Son ideales para crear subcategorizaciones o ejecutar procesos personalizados.

### Ejemplo: Consultas sobre productos

Supongamos que Tomy recibe muchas consultas sobre productos que requieren clasificaci√≥n m√°s espec√≠fica. Podemos crear una acci√≥n para el t√≥pico "Consulta_Producto":

```javascript
import { orchestrator } from 'ludmi';

const response = await orchestrator({
  history,
  input,
  sizeHistory: 5,
  topics,
  userData,
  actions: {
    "Consulta_Producto": consultaProductoAction
  },
  metadata: {
    currentYear: Date.now(),
    mainTheme: "Soy Tomy, especialista en verduras y frutas frescas de temporada."
  }
});
```

### Implementando la acci√≥n

```javascript
import { classifier } from 'ludmi';

export const consultaProductoAction = async ({ input, revised_prompt, userData, history }) => {
  
  // Segunda capa de clasificaci√≥n para productos espec√≠ficos
  const respClassifier = await classifier({
    input: revised_prompt,
    topics: [
      {
        name: "precios",
        description: "El usuario pregunta sobre precios de productos. Ejemplo: '¬øCu√°nto cuesta?', '¬øQu√© precio tiene?'"
      },
      {
        name: "disponibilidad", 
        description: "El usuario pregunta si hay stock o disponibilidad. Ejemplo: '¬øTienen tomates?', '¬øHay lechuga?'"
      },
      {
        name: "calidad",
        description: "El usuario pregunta sobre frescura, calidad o estado de los productos. Ejemplo: '¬øEst√°n frescos?', '¬øSon org√°nicos?'"
      },
      {
        name: "temporada",
        description: "El usuario pregunta sobre productos de temporada. Ejemplo: '¬øQu√© verduras hay ahora?', '¬øQu√© est√° en temporada?'"
      }
    ]
  });

  return {
    price: respClassifier.price,
    eval: {
      subtopic: respClassifier.topic,
      category: "producto"
    }
  };
};
```

### C√≥mo funcionan las acciones

1. **Ejecuci√≥n autom√°tica**: Cuando el orquestador clasifica un t√≥pico que tiene una acci√≥n asociada, la ejecuta autom√°ticamente.

2. **L√≥gica personalizada**: Dentro de la acci√≥n puedes implementar cualquier l√≥gica:
   - Subclasificaciones (como en el ejemplo)
   - Llamadas a APIs externas
   - Consultas a bases de datos
   - Validaciones espec√≠ficas

3. **Informaci√≥n adicional**: Todo lo que devuelvas en `eval` se incluye en la respuesta final del orquestador.

4. **Control de costos**: Los precios de las acciones se suman al costo total de la operaci√≥n.

### Respuesta con acci√≥n ejecutada

```json
{
  "price": {
    "unit": "USD", 
    "value": 0.00013065
  },
  "data": {
    "history": [
      {
        "role": "assistant",
        "content": "¬°Hola! Soy Tomy, tu verdulero virtual."
      },
      {
        "role": "user",
        "content": "¬øTienen tomates frescos?"
      }
    ],
    "input": "¬øTienen tomates frescos?",
    "revised_prompt": "¬øTienen tomates frescos disponibles?",
    "topic": "Consulta_Producto", 
    "userData": {},
    "eval": {
      "subtopic": "disponibilidad",
      "category": "producto"
    }
  }
}
```

### Ventajas de las acciones

- **Clasificaci√≥n multinivel**: Crea jerarqu√≠as de t√≥picos para mayor precisi√≥n
- **Flexibilidad total**: Ejecuta cualquier l√≥gica personalizada
- **Integraci√≥n externa**: Conecta con APIs, bases de datos o servicios externos
- **Informaci√≥n enriquecida**: A√±ade contexto adicional a las respuestas
- **Control granular**: Gestiona diferentes flujos seg√∫n el contexto espec√≠fico

Con las acciones, Tomy puede manejar consultas complejas y proporcionar respuestas mucho m√°s precisas y contextuales.

## Generaci√≥n de respuestas autom√°ticas

Adem√°s de clasificar t√≥picos para que tu frontend decida qu√© mostrar, **LU puede generar respuestas autom√°ticamente** usando inteligencia artificial. Esto es ideal para manejar consultas complejas o casos especiales.

### Configurando respuestas autom√°ticas

Vamos a crear una acci√≥n que genere respuestas autom√°ticas cuando Tomy no pueda categorizar bien una consulta:

```javascript
import { orchestrator } from 'ludmi';

const response = await orchestrator({
  history,
  input,
  sizeHistory: 5,
  topics,
  userData,
  actions: {
    "Consulta_Producto": consultaProductoAction,
    "Consulta_General": consultaGeneralAction  // Nueva acci√≥n con IA
  },
  metadata: {
    currentYear: Date.now(),
    mainTheme: "Soy Tomy, especialista en verduras y frutas frescas."
  }
});
```

### Implementando respuesta autom√°tica

```javascript
import { getAIResponse } from 'ludmi';

export const consultaGeneralAction = async ({ input, revised_prompt, userData, history }) => {

  const developerInstruction = `Eres Tomy, un verdulero experto que conoce todo sobre:
- Verduras y frutas frescas de temporada
- Precios actuales del mercado
- Consejos de conservaci√≥n y preparaci√≥n
- Recetas simples con ingredientes frescos
- Diferencias entre productos org√°nicos y convencionales

Informaci√≥n del negocio:
- Horarios: Lunes a S√°bado de 8:00 a 20:00
- Delivery disponible en zona norte
- Productos org√°nicos certificados disponibles
- Especialidad en verduras de hoja y frutas de estaci√≥n

# Personalidad de Tomy
- Amigable y cercano, como un verdulero de barrio
- Conocimiento profundo pero explicado de manera simple
- Siempre dispuesto a dar consejos pr√°cticos
- Usa un lenguaje coloquial pero profesional
- Incluye recomendaciones personalizadas

# Reglas
- Si la consulta no est√° relacionada con verduras, frutas o el negocio, redirige amablemente
- Siempre sugiere productos frescos y de temporada
- Menciona beneficios nutricionales cuando sea relevante
- Ofrece alternativas si algo no est√° disponible
`;

  const messages = [
    {
      role: "developer", 
      content: developerInstruction
    },
    {
      role: "user",
      content: revised_prompt
    }
  ];

  // Generar respuesta autom√°tica con IA
  const { content, price } = await getAIResponse({
    messages,
    model: "gpt-4o-mini",
    temperature: 0.7
  });

  return {
    price: price,
    eval: {
      topic: "consulta_general",
      content,
      generated: true
    }
  };
};
```

### Respuesta con contenido generado

```json
{
  "price": {
    "unit": "USD",
    "value": 0.00025430
  },
  "data": {
    "history": [
      {
        "role": "assistant", 
        "content": "¬°Hola! Soy Tomy, tu verdulero de confianza."
      },
      {
        "role": "user",
        "content": "¬øQu√© me recomend√°s para hacer una ensalada fresca?"
      }
    ],
    "input": "¬øQu√© me recomend√°s para hacer una ensalada fresca?",
    "revised_prompt": "¬øQu√© me recomend√°s para hacer una ensalada fresca y nutritiva?",
    "topic": "Consulta_General",
    "userData": {},
    "eval": {
      "topic": "consulta_general",
      "content": "¬°Excelente pregunta! Para una ensalada fresca te recomiendo:\n\n**Base verde**: Lechuga mantecosa o r√∫cula (est√°n perfectas ahora)\n**Colores**: Tomate cherry, zanahoria rallada y pimiento rojo\n**Frescura**: Pepino y apio para el crunch\n**Toque especial**: Palta madura y unos brotes de alfalfa\n\nüí° **Tip del d√≠a**: La r√∫cula que tengo hoy est√° s√∫per fresca, le va a dar un sabor incre√≠ble a tu ensalada. ¬°Y la palta est√° en su punto justo!\n\n¬øQuer√©s que te arme un combo con todo esto?",
      "generated": true
    }
  }
}
```

### Funci√≥n auxiliar: JSONparse

LU incluye una utilidad especial para parsear respuestas JSON de LLMs:

```javascript
import { JSONparse } from 'ludmi';

// Los LLMs a veces devuelven JSON envuelto en markdown
const llmResponse = "```json\n{\"producto\": \"tomate\", \"precio\": 500}\n```";

// JSON.parse fallar√≠a, pero JSONparse lo maneja
const parsed = JSONparse(llmResponse);
console.log(parsed); // { producto: "tomate", precio: 500 }
```

### Ventajas de las respuestas autom√°ticas

- **Flexibilidad total**: Maneja consultas impredecibles con inteligencia artificial
- **Personalizaci√≥n**: Define la personalidad y conocimientos espec√≠ficos del bot
- **Contextual**: Usa el historial y datos del usuario para respuestas relevantes
- **Control de costos**: Monitorea el gasto por cada respuesta generada
- **Fallback inteligente**: Ideal para casos que no encajan en t√≥picos predefinidos

Con esta funcionalidad, Tomy puede responder de manera inteligente a pr√°cticamente cualquier consulta relacionada con su dominio de conocimiento.

## Creando bases de conocimiento

LU te permite convertir tus datos estructurados en bases de conocimiento inteligentes que pueden ser consultadas sem√°nticamente. Esto es ideal para que Tomy acceda a informaci√≥n espec√≠fica sobre productos, precios y stock.

### knowledgeBaseByJSON

Convierte datos JSON en fragmentos embebidos listos para b√∫squeda sem√°ntica:

```javascript
const { knowledgeBaseByJSON } = require("ludmi");
const productos = require("./db/productos.json");

const embeddings = await knowledgeBaseByJSON({
  json: productos,
  id: "nombre",          // Campo que se usar√° como identificador
  maxTokens: 800,        // Tokens m√°ximos por fragmento
  overlapTokens: 40      // Tokens de solapamiento entre fragmentos
});
```

### Ejemplo de datos para Tomy

Supongamos que tienes un archivo `productos.json` con informaci√≥n est√°tica de tus productos:

```json
[
  {
    "nombre": "Tomate perita",
    "categoria": "tomates",
    "unidad": "kg",
    "temporada": "todo el a√±o",
    "origen": "Mendoza",
    "variedades": ["com√∫n", "org√°nico"],
    "usos": ["salsas", "conservas", "ensaladas"],
    "descripcion": "Tomates peritas frescos, forma alargada, ideales para salsas y conservas por su pulpa carnosa"
  },
  {
    "nombre": "Lechuga mantecosa",
    "categoria": "verduras de hoja",
    "unidad": "unidad",
    "temporada": "oto√±o-invierno", 
    "origen": "Buenos Aires",
    "variedades": ["com√∫n", "org√°nica"],
    "usos": ["ensaladas", "hamburguesas", "wraps"],
    "descripcion": "Lechuga de hojas tiernas y dulces, textura mantecosa, perfecta para ensaladas frescas"
  },
  {
    "nombre": "Papa colorada",
    "categoria": "tub√©rculos",
    "unidad": "kg",
    "temporada": "todo el a√±o",
    "origen": "Balcarce",
    "variedades": ["com√∫n", "org√°nica"],
    "usos": ["pur√©", "hervida", "al horno", "papas fritas"],
    "descripcion": "Papa de piel rojiza, pulpa amarilla, ideal para hervir y hacer pur√©"
  }
]
```

### Par√°metros de configuraci√≥n

- **`id`**: Campo del JSON que se conservar√° como identificador √∫nico
- **`maxTokens`**: Cantidad m√°xima de tokens por fragmento (recomendado: 800)
- **`overlapTokens`**: Tokens que se superponen entre fragmentos cuando el contenido es muy largo

### Resultado procesado

```json
[
  {
    "id": "Tomate perita",
    "fragmentIndex": 0,
    "text": "{\"nombre\":\"Tomate perita\", \"categoria\": \"tomates\", \"unidad\": \"kg\", \"temporada\": \"todo el a√±o\", \"origen\": \"Mendoza\", \"variedades\": [\"com√∫n\", \"org√°nico\"], \"usos\": [\"salsas\", \"conservas\", \"ensaladas\"]}",
    "embedding": [0.003612947, -0.023726178, -0.011756117, ...]
  },
  {
    "id": "Tomate perita",
    "fragmentIndex": 1,
    "text": "\"descripcion\": \"Tomates peritas frescos, forma alargada, ideales para salsas y conservas por su pulpa carnosa\"",
    "embedding": [0.002456789, -0.018765432, -0.009123456, ...]
  },
  {
    "id": "Lechuga mantecosa", 
    "fragmentIndex": 0,
    "text": "{\"nombre\":\"Lechuga mantecosa\", \"categoria\": \"verduras de hoja\", \"unidad\": \"unidad\", \"temporada\": \"oto√±o-invierno\", \"origen\": \"Buenos Aires\", \"variedades\": [\"com√∫n\", \"org√°nica\"]}",
    "embedding": [-0.002345678, -0.015678912, -0.009876543, ...]
  }
]
```

### Flujo completo: KB + Base de datos

El enfoque recomendado es usar la base de conocimiento para **identificar productos** y luego consultar tu base de datos para **informaci√≥n din√°mica**:

```javascript
// 1. Usuario pregunta: "¬øCu√°nto cuesta el tomate?"
// 2. La KB identifica: "Tomate perita" 
// 3. Consultas tu BD para precio/stock actual:

const productoIdentificado = "Tomate perita";
const infoDinamica = await consultarBD(productoIdentificado);
// { precio: 1200, stock: 45, oferta: false }

// 4. Combinas info est√°tica + din√°mica para responder
```

### Fragmentaci√≥n inteligente

Cuando un producto tiene mucha informaci√≥n (descripci√≥n larga, m√∫ltiples campos), LU autom√°ticamente:

1. **Divide el contenido** en fragmentos que no excedan `maxTokens`
2. **Mantiene conexi√≥n** usando `overlapTokens` para preservar contexto
3. **Asigna √≠ndices** (`fragmentIndex`) para identificar las partes
4. **Conserva el ID** para relacionar todos los fragmentos del mismo elemento

### Ventajas para Tomy

- **Identificaci√≥n inteligente**: Encuentra productos por sin√≥nimos ("tomate cherry" ‚Üí "Tomate perita")
- **Informaci√≥n rica**: Accede a categor√≠as, usos, temporadas y caracter√≠sticas
- **Separaci√≥n clara**: KB para identificar, BD para datos que cambian
- **B√∫squeda flexible**: "verdura para ensalada" puede encontrar m√∫ltiples opciones
- **Escalabilidad**: Maneja cat√°logos grandes manteniendo datos din√°micos separados

La base de conocimiento act√∫a como un "diccionario inteligente" que identifica productos, mientras que tu base de datos tradicional maneja precios y stock en tiempo real.

### knowledgeBaseByText

Convierte documentos de texto largo en fragmentos embebidos para b√∫squeda sem√°ntica. Ideal para manuales, gu√≠as o documentaci√≥n que Tomy pueda consultar:

```javascript
const { knowledgeBaseByText } = require("ludmi");
const fs = require('fs');

// Leer un documento de texto
const guiaVerduras = fs.readFileSync('./docs/guia-verduras.txt', 'utf8');

const embeddings = await knowledgeBaseByText({
  text: guiaVerduras,
  maxTokens: 800,        // Tokens m√°ximos por fragmento
  overlapTokens: 40      // Tokens de solapamiento entre fragmentos
});
```

### Ejemplo de documento para Tomy

Supongamos que tienes una gu√≠a con informaci√≥n especializada:

```text
# Gu√≠a del Verdulero Experto

## Temporadas de Verduras

Las verduras de temporada no solo son m√°s sabrosas, sino tambi√©n m√°s econ√≥micas y nutritivas. Durante el oto√±o, las verduras de hoja como lechuga, espinaca y acelga est√°n en su mejor momento. 

La lechuga mantecosa alcanza su m√°xima dulzura entre marzo y junio, cuando las temperaturas frescas favorecen el desarrollo de hojas tiernas. Es importante conservarla en el caj√≥n de verduras de la heladera, envuelta en papel absorbente.

## Conservaci√≥n y Almacenamiento

Los tomates nunca deben refrigerarse si no est√°n completamente maduros, ya que el fr√≠o interrumpe el proceso de maduraci√≥n y afecta su sabor. Los tomates peritas son ideales para conservas debido a su menor contenido de agua y mayor concentraci√≥n de pulpa.

## Consejos Nutricionales

Las verduras de color verde oscuro como la espinaca y el br√≥coli son ricas en hierro y √°cido f√≥lico. Se recomienda consumirlas junto con alimentos ricos en vitamina C para mejorar la absorci√≥n del hierro.
```

### Resultado procesado

```json
[
  {
    "fragmentIndex": 0,
    "text": "# Gu√≠a del Verdulero Experto\n\n## Temporadas de Verduras\n\nLas verduras de temporada no solo son m√°s sabrosas, sino tambi√©n m√°s econ√≥micas y nutritivas. Durante el oto√±o, las verduras de hoja como lechuga, espinaca y acelga est√°n en su mejor momento.",
    "embedding": [-0.027951738, -0.027387531, 0.010966767, ...]
  },
  {
    "fragmentIndex": 1,
    "text": "est√°n en su mejor momento.\n\nLa lechuga mantecosa alcanza su m√°xima dulzura entre marzo y junio, cuando las temperaturas frescas favorecen el desarrollo de hojas tiernas. Es importante conservarla en el caj√≥n de verduras",
    "embedding": [-0.025413267, -0.023891045, 0.008745632, ...]
  },
  {
    "fragmentIndex": 2,
    "text": "conservarla en el caj√≥n de verduras de la heladera, envuelta en papel absorbente.\n\n## Conservaci√≥n y Almacenamiento\n\nLos tomates nunca deben refrigerarse si no est√°n completamente maduros",
    "embedding": [-0.022876543, -0.021456789, 0.009876543, ...]
  }
]
```

### Diferencias con knowledgeBaseByJSON

- **Sin par√°metro `id`**: No hay identificadores √∫nicos, solo √≠ndices secuenciales
- **Fragmentaci√≥n autom√°tica**: Divide el texto largo seg√∫n `maxTokens`
- **Solapamiento crucial**: `overlapTokens` mantiene continuidad entre fragmentos
- **Contenido continuo**: Ideal para documentos narrativos o explicativos

### Casos de uso para Tomy

- **Gu√≠as de temporada**: Informaci√≥n sobre cu√°ndo est√°n mejor las verduras
- **Consejos de conservaci√≥n**: C√≥mo mantener productos frescos
- **Recetas y preparaci√≥n**: Sugerencias culinarias
- **Informaci√≥n nutricional**: Beneficios de cada producto
- **Historia y origen**: Datos curiosos sobre productos

### Ventajas del texto embebido

- **B√∫squeda contextual**: Encuentra informaci√≥n relevante por contexto
- **Conocimiento profundo**: Accede a informaci√≥n especializada
- **Respuestas fundamentadas**: Basa respuestas en documentaci√≥n real
- **Actualizaci√≥n f√°cil**: Modifica el documento y regenera embeddings
- **Flexibilidad**: Funciona con cualquier tipo de texto estructurado

Con ambas funciones (`knowledgeBaseByJSON` y `knowledgeBaseByText`), Tomy puede combinar datos estructurados de productos con conocimiento experto en formato de texto.

## Recuperaci√≥n inteligente de informaci√≥n

Una vez que tienes tus bases de conocimiento embebidas, puedes usar **retriever** y **RAG** para que Tomy encuentre informaci√≥n espec√≠fica y genere respuestas fundamentadas.

### Usando el retriever

El retriever busca los fragmentos m√°s relevantes seg√∫n la consulta del usuario:

```javascript
import { retriever } from 'ludmi';

const chunks = await retriever({
  revised_prompt,           // Entrada procesada por el orquestador
  data: baseConocimiento,   // Tu base de conocimiento embebida
  size: 3                   // Cantidad de fragmentos a recuperar
});
```

### Ejemplo con la gu√≠a de Tomy

```javascript
// El usuario pregunta: "¬øC√≥mo conservar las lechugas?"
const chunks = await retriever({
  revised_prompt: "¬øC√≥mo conservar las lechugas frescas por m√°s tiempo?",
  data: guiaEmbebida,       // Base de conocimiento de la gu√≠a del verdulero
  size: 2                   // Los 2 fragmentos m√°s relevantes
});

// Resultado: fragmentos sobre conservaci√≥n de verduras de hoja
```

### Generando respuestas con RAG

RAG (Retrieval-Augmented Generation) combina los fragmentos recuperados con IA para generar respuestas contextuales:

```javascript
import { rag } from 'ludmi';

// Crear prompt personalizado para Tomy
const prompt = `Responder usando solo la informaci√≥n de la base de conocimiento: \`${JSON.stringify(chunks)}\`

# Reglas
- Solo ayudar con consultas sobre verduras, frutas y alimentaci√≥n saludable
- Si no hay informaci√≥n relevante, sugerir consultar en el local

# Personalidad de Tomy
- Amigable y cercano, como un verdulero de barrio con experiencia
- Conocimiento pr√°ctico y consejos √∫tiles
- Lenguaje sencillo pero informativo
- Siempre incluye tips extra cuando sea relevante
- Ocasionalmente menciona productos de temporada
`;

// Generar respuesta fundamentada
const respuesta = await rag({
  chunks,
  prompt,
  revised_prompt
});

console.log(respuesta);
// { content: "Para conservar lechugas frescas...", price: 0.00012 }
```

### Par√°metros de RAG

La funci√≥n `rag` acepta m√∫ltiples configuraciones:

```javascript
const respuesta = await rag({
  chunks,                    // Fragmentos recuperados
  revised_prompt,           // Entrada del usuario procesada
  prompt,                   // Prompt personalizado (opcional)
  conversation,             // Historial completo (alternativa a revised_prompt)
  userData,                 // Datos del usuario para personalizaci√≥n
  model: "gpt-4o-mini"     // Modelo a usar (por defecto gpt-4o-mini)
});
```

### Flujo completo: De consulta a respuesta

```javascript
// 1. Usuario pregunta sobre conservaci√≥n
const userInput = "¬øC√≥mo mantengo frescas las verduras de hoja?";

// 2. Orquestador procesa y enriquece
const { data } = await orchestrator({
  input: userInput,
  // ... otros par√°metros
});

// 3. Retriever encuentra informaci√≥n relevante
const chunks = await retriever({
  revised_prompt: data.revised_prompt,
  data: guiaVerduleroEmbebida,
  size: 3
});

// 4. RAG genera respuesta fundamentada
const respuesta = await rag({
  chunks,
  prompt: promptTomy,
  revised_prompt: data.revised_prompt
});

// 5. Respuesta final para el usuario
console.log(respuesta.content);
// "Para mantener frescas las verduras de hoja como lechuga y espinaca, 
//  te recomiendo guardarlas en el caj√≥n de verduras envueltas en papel 
//  absorbente. Esto mantiene la humedad justa sin que se pudran..."
```

### Ventajas del sistema RAG

- **Respuestas fundamentadas**: Basadas en informaci√≥n real de tu base de conocimiento
- **Actualizable**: Cambia la documentaci√≥n y las respuestas se actualizan
- **Precisi√≥n**: Solo usa informaci√≥n que realmente tienes
- **Personalizable**: Adapta la personalidad y estilo de respuesta
- **Eficiente**: Encuentra informaci√≥n relevante sin procesar todo el conocimiento

Con retriever + RAG, Tomy puede actuar como un verdadero experto que consulta su conocimiento especializado para dar respuestas precisas y √∫tiles.